{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to teach a robot to walk on an uneven terrain? \n",
    "\n",
    "Open AI Gym has many great environments for experimenting with reinforcement learning. In this notebook I'll use the **Bipedal Walker Hardcore v2** env. to teach an agent in a robot's body to walk. Inspiration from [this](https://github.com/jet-black/ppo-lstm-parallel) project.  \n",
    "*Note: To run this code you'll need to install SWIG and Box2D*\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from master import SimpleMaster\n",
    "import environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(env, gpu):\n",
    "    env_name = env\n",
    "\n",
    "    if not os.path.exists('logs'):\n",
    "        os.mkdir('logs')\n",
    "\n",
    "    if not os.path.exists('models'):\n",
    "        os.mkdir('models')\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(\"logs/\" + env_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    env_producer = environments.EnvironmentProducer(env_name, gpu)\n",
    "    master = SimpleMaster(env_producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_dim : 4\n",
      "env_name : BipedalWalker-v2\n",
      "state_dim : 24\n",
      "action_dim : 4\n",
      "discrete : False\n",
      "action_dim : 4\n",
      "env_name : BipedalWalker-v2\n",
      "env_name : BipedalWalker-v2\n",
      "scales_lo : [-1. -1. -1. -1.]\n",
      "state_dim : 24\n",
      "state_dim : 24\n",
      "scales_hi : [1. 1. 1. 1.]\n",
      "discrete : False\n",
      "scales_lo : [-1. -1. -1. -1.]\n",
      "scales_hi : [1. 1. 1. 1.]\n",
      "max_episode_steps : 1600\n",
      "use_gpu : \n",
      "clip_eps : 0.2\n",
      "discrete : False\n",
      "max_episode_steps : 1600\n",
      "grad_step : 0.0001\n",
      "scales_lo : [-1. -1. -1. -1.]\n",
      "use_gpu : \n",
      "scales_hi : [1. 1. 1. 1.]\n",
      "clip_eps : 0.2\n",
      "discount_factor : 0.99\n",
      "max_episode_steps : 1600\n",
      "gae_factor : 0.98\n",
      "use_gpu : \n",
      "batch_size : 4096\n",
      "clip_eps : 0.2\n",
      "rollout_size : 8192\n",
      "grad_step : 0.0001\n",
      "epochs : 10\n",
      "discount_factor : 0.99\n",
      "entropy_coef : 0.0\n",
      "hidden_layer_size : 128\n",
      "timestep_size : 8\n",
      "kl_target : 0.01\n",
      "use_kl_loss : True\n",
      "init_beta : 1.0\n",
      "eta : 30\n",
      "recurrent : False\n",
      "grad_step : 0.0001\n",
      "worker_num : 1\n",
      "gae_factor : 0.98\n",
      "discount_factor : 0.99\n",
      "gather_per_worker : 2\n",
      "batch_size : 4096\n",
      "nn_std : False\n",
      "rollout_size : 8192\n",
      "gae_factor : 0.98\n",
      "reward_transform : scale\n",
      "batch_size : 4096\n",
      "discretize_space : False\n",
      "rollout_size : 8192\n",
      "mem_fraction : 0.32666666666666666\n",
      "epochs : 10\n",
      "entropy_coef : 0.0\n",
      "hidden_layer_size : 128\n",
      "timestep_size : 8\n",
      "epochs : 10\n",
      "kl_target : 0.01\n",
      "entropy_coef : 0.0\n",
      "hidden_layer_size : 128\n",
      "timestep_size : 8\n",
      "use_kl_loss : True\n",
      "init_beta : 1.0\n",
      "eta : 30\n",
      "recurrent : False\n",
      "worker_num : 1\n",
      "gather_per_worker : 2\n",
      "nn_std : False\n",
      "reward_transform : scale\n",
      "discretize_space : False\n",
      "kl_target : 0.01\n",
      "mem_fraction : 0.32666666666666666\n",
      "use_kl_loss : True\n",
      "init_beta : 1.0\n",
      "eta : 30\n",
      "recurrent : False\n",
      "worker_num : 1\n",
      "gather_per_worker : 2\n",
      "nn_std : False\n",
      "reward_transform : scale\n",
      "discretize_space : False\n",
      "mem_fraction : 0.32666666666666666\n",
      "action_dim : 4\n",
      "env_name : BipedalWalker-v2\n",
      "state_dim : 24\n",
      "discrete : False\n",
      "scales_lo : [-1. -1. -1. -1.]\n",
      "scales_hi : [1. 1. 1. 1.]\n",
      "max_episode_steps : 1600\n",
      "use_gpu : \n",
      "clip_eps : 0.2\n",
      "grad_step : 0.0001\n",
      "discount_factor : 0.99\n",
      "gae_factor : 0.98\n",
      "batch_size : 4096\n",
      "rollout_size : 8192\n",
      "epochs : 10\n",
      "entropy_coef : 0.0\n",
      "hidden_layer_size : 128\n",
      "timestep_size : 8\n",
      "kl_target : 0.01\n",
      "use_kl_loss : True\n",
      "init_beta : 1.0\n",
      "eta : 30\n",
      "recurrent : False\n",
      "worker_num : 1\n",
      "gather_per_worker : 2\n",
      "nn_std : False\n",
      "reward_transform : scale\n",
      "discretize_space : False\n",
      "mem_fraction : 0.32666666666666666\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/policy.py:714: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:199: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:205: TransformedDistribution.__init__ (from tensorflow.python.ops.distributions.transformed_distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "WARNING:tensorflow:From /home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/policy.py:714: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "WARNING:tensorflow:From /home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/policy.py:714: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/policy.py:714: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:199: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:205: TransformedDistribution.__init__ (from tensorflow.python.ops.distributions.transformed_distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:199: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:199: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:205: TransformedDistribution.__init__ (from tensorflow.python.ops.distributions.transformed_distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:205: TransformedDistribution.__init__ (from tensorflow.python.ops.distributions.transformed_distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:1173: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/kullback_leibler.py:107: _kl_brute_force (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:1173: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/kullback_leibler.py:107: _kl_brute_force (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:1173: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/kullback_leibler.py:107: _kl_brute_force (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:1173: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/kullback_leibler.py:107: _kl_brute_force (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:163: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:163: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:163: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:163: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/BipedalWalker-v2/model-186120\n",
      "Average reward: 306.4666569605669\n",
      "Average reward: 306.0399966842322\n",
      "Average reward: 305.917415837466\n",
      "Average reward: 306.8643514969479\n",
      "Average reward: 305.4121836512305\n",
      "Average reward: 306.74901631571424\n",
      "Average reward: 277.8800097430457\n",
      "Average reward: 306.22436443804224\n",
      "Average reward: 268.6291111941227\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 306.98589932470884\n",
      "Average reward: 305.518307889715\n",
      "Average reward: 306.10819170997365\n",
      "Average reward: 305.4635694730399\n",
      "Average reward: 306.67318039250694\n",
      "Average reward: 305.9392120186383\n",
      "Average reward: 305.56607665803506\n",
      "Average reward: 305.7870871285272\n",
      "Average reward: 305.6362867231778\n",
      "Average reward: 304.72684660775906\n",
      "Saving model...\n",
      "WARNING:tensorflow:From /home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Model saved\n",
      "Average reward: 305.59234150996315\n",
      "Average reward: 306.36018457154114\n",
      "Average reward: 238.18531121730538\n",
      "Average reward: 305.24427793471136\n",
      "Average reward: 305.4894314775814\n",
      "Average reward: 263.2792562296253\n",
      "Average reward: 305.71786479434917\n",
      "Average reward: 306.4706484634416\n",
      "Average reward: 305.8316478253177\n",
      "Average reward: 256.4312094523584\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 304.71903318255704\n",
      "Average reward: 305.74388561697333\n",
      "Average reward: 305.3685177367\n",
      "Average reward: 305.1184739014755\n",
      "Average reward: 305.607375509517\n",
      "Average reward: 241.8715978261548\n",
      "Average reward: 306.0520647327983\n",
      "Average reward: 306.317391596937\n",
      "Average reward: 306.0571005505984\n",
      "Average reward: 284.9220358014964\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 306.1018299382058\n",
      "Average reward: 306.65029220316706\n",
      "Average reward: 306.5598088531707\n",
      "Average reward: 306.68497508993346\n",
      "Average reward: 306.96995938850694\n",
      "Average reward: 305.8400399849467\n",
      "Average reward: 306.84734948179437\n",
      "Average reward: 308.2410516404392\n",
      "Average reward: 308.0186549080409\n",
      "Average reward: 270.1855451821533\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.28003448356856\n",
      "Average reward: 307.94137110736585\n",
      "Average reward: 308.38195775840813\n",
      "Average reward: 269.61854796798264\n",
      "Average reward: 307.74162190526187\n",
      "Average reward: 262.82682886865155\n",
      "Average reward: 307.11366542874197\n",
      "Average reward: 307.46033396253046\n",
      "Average reward: 307.70320975047247\n",
      "Average reward: 266.8336500155595\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 263.4990232542947\n",
      "Average reward: 307.22127742182647\n",
      "Average reward: 230.1372381176463\n",
      "Average reward: 307.22734241857614\n",
      "Average reward: 307.58314619100463\n",
      "Average reward: 306.5377671055839\n",
      "Average reward: 307.3051879778709\n",
      "Average reward: 307.8556031458976\n",
      "Average reward: 266.6412104065329\n",
      "Average reward: 306.84849215520967\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.93021840156064\n",
      "Average reward: 307.85791343762384\n",
      "Average reward: 308.19285342316414\n",
      "Average reward: 307.26531369433195\n",
      "Average reward: 268.8847367182328\n",
      "Average reward: 308.0269021366551\n",
      "Average reward: 307.9334100427868\n",
      "Average reward: 280.8866660906177\n",
      "Average reward: 307.06649156008945\n",
      "Average reward: 307.4996084976342\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.45982482967173\n",
      "Average reward: 273.18058226142915\n",
      "Average reward: 307.8876631855882\n",
      "Average reward: 279.4585392066758\n",
      "Average reward: 307.40625993074104\n",
      "Average reward: 307.59314902355925\n",
      "Average reward: 307.7111653694945\n",
      "Average reward: 308.31370467936233\n",
      "Average reward: 266.5755101502451\n",
      "Average reward: 308.24406250439336\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 255.57132081423785\n",
      "Average reward: 308.2797788030716\n",
      "Average reward: 307.30526860187376\n",
      "Average reward: 308.3527935862065\n",
      "Average reward: 308.74948489892034\n",
      "Average reward: 308.7988412794165\n",
      "Average reward: 309.22348966787644\n",
      "Average reward: 309.195651188715\n",
      "Average reward: 308.27069355947975\n",
      "Average reward: 308.3198140138081\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 266.0565179439514\n",
      "Average reward: 308.70978839252433\n",
      "Average reward: 309.11634254833575\n",
      "Average reward: 308.62486968596966\n",
      "Average reward: 238.8621647147444\n",
      "Average reward: 308.58984187434163\n",
      "Average reward: 308.64997844728725\n",
      "Average reward: 281.0963893966016\n",
      "Average reward: 251.41730618409767\n",
      "Average reward: 308.28501752425683\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.16059697917535\n",
      "Average reward: 245.92485868213763\n",
      "Average reward: 309.122272527614\n",
      "Average reward: 308.1654263973206\n",
      "Average reward: 308.21003768136393\n",
      "Average reward: 308.45049487222025\n",
      "Average reward: 308.8036505886761\n",
      "Average reward: 308.336215517408\n",
      "Average reward: 309.4588585329143\n",
      "Average reward: 276.1733451451569\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.1261977229672\n",
      "Average reward: 307.88757644972\n",
      "Average reward: 309.1276193076245\n",
      "Average reward: 308.7935281323245\n",
      "Average reward: 283.4791899890615\n",
      "Average reward: 309.081643690496\n",
      "Average reward: 308.55738098368766\n",
      "Average reward: 183.08275785991884\n",
      "Average reward: 309.79221221183406\n",
      "Average reward: 308.99850620764863\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 247.83663634533832\n",
      "Average reward: 310.65304184223135\n",
      "Average reward: 308.8822075620202\n",
      "Average reward: 309.01415220554065\n",
      "Average reward: 282.23494157231227\n",
      "Average reward: 309.5029765410883\n",
      "Average reward: 309.49678083646194\n",
      "Average reward: 265.175424412357\n",
      "Average reward: 310.25700566761213\n",
      "Average reward: 308.83694873763386\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.66154111400255\n",
      "Average reward: 309.40554591586283\n",
      "Average reward: 309.422884927899\n",
      "Average reward: 258.05441343992555\n",
      "Average reward: 283.3017532248493\n",
      "Average reward: 309.4231145007275\n",
      "Average reward: 309.32933123095097\n",
      "Average reward: 308.23911245374404\n",
      "Average reward: 265.5367146798738\n",
      "Average reward: 309.2180104040249\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.54425497189936\n",
      "Average reward: 309.1955875870245\n",
      "Average reward: 310.18563891032863\n",
      "Average reward: 308.7205698805368\n",
      "Average reward: 309.61249830223744\n",
      "Average reward: 309.54674787167335\n",
      "Average reward: 309.22412044145665\n",
      "Average reward: 309.6824715400604\n",
      "Average reward: 261.9962512317069\n",
      "Average reward: 197.6540285790261\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.393965750891\n",
      "Average reward: 309.22142258222027\n",
      "Average reward: 308.39048181129664\n",
      "Average reward: 308.177327027208\n",
      "Average reward: 308.8532635911448\n",
      "Average reward: 308.852361205193\n",
      "Average reward: 248.2267328838488\n",
      "Average reward: 276.54471284629176\n",
      "Average reward: 281.2552904361103\n",
      "Average reward: 308.73060718930554\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 266.1745994792329\n",
      "Average reward: 200.54038960413934\n",
      "Average reward: 308.7664238830498\n",
      "Average reward: 307.9264738323331\n",
      "Average reward: 307.65184681099635\n",
      "Average reward: 308.283849895976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 308.9633297366123\n",
      "Average reward: 279.57441134904593\n",
      "Average reward: 308.8039465706055\n",
      "Average reward: 307.53040463306485\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.99036669845776\n",
      "Average reward: 308.37091017485375\n",
      "Average reward: 307.9955820162386\n",
      "Average reward: 239.2395898364217\n",
      "Average reward: 307.8418410691864\n",
      "Average reward: 258.91143857689497\n",
      "Average reward: 308.37370043452717\n",
      "Average reward: 308.0827546404136\n",
      "Average reward: 308.59184754337514\n",
      "Average reward: 307.5139761796334\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.2793764646576\n",
      "Average reward: 308.3807094655172\n",
      "Average reward: 308.17241069755477\n",
      "Average reward: 274.4632148908206\n",
      "Average reward: 259.4163659749793\n",
      "Average reward: 308.21224815727675\n",
      "Average reward: 308.1176381282496\n",
      "Average reward: 307.7805402578409\n",
      "Average reward: 245.3689096247112\n",
      "Average reward: 271.974551387765\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.8376794764296\n",
      "Average reward: 308.0127795872886\n",
      "Average reward: 307.86454059639755\n",
      "Average reward: 308.12361105906155\n",
      "Average reward: 308.3979749419947\n",
      "Average reward: 252.04593341303135\n",
      "Average reward: 308.10032490805827\n",
      "Average reward: 308.10588378963945\n",
      "Average reward: 256.1052710827736\n",
      "Average reward: 307.7592673864374\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.46146676618633\n",
      "Average reward: 227.53453764131183\n",
      "Average reward: 308.16961074918004\n",
      "Average reward: 308.0895726943644\n",
      "Average reward: 307.7612772124192\n",
      "Average reward: 308.4111327719504\n",
      "Average reward: 308.1195274608336\n",
      "Average reward: 283.32542442699224\n",
      "Average reward: 308.95227642680857\n",
      "Average reward: 251.2824500346474\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 241.71199429935746\n",
      "Average reward: 308.3803267276681\n",
      "Average reward: 281.5197858425222\n",
      "Average reward: 280.160613007558\n",
      "Average reward: 308.72409904478616\n",
      "Average reward: 307.99830474474936\n",
      "Average reward: 308.6531811464041\n",
      "Average reward: 307.76843992851354\n",
      "Average reward: 307.1701768228518\n",
      "Average reward: 263.2450502752109\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.80243124480916\n",
      "Average reward: 307.60333859520904\n",
      "Average reward: 308.1433327736146\n",
      "Average reward: 307.6013313057284\n",
      "Average reward: 307.4716605437753\n",
      "Average reward: 307.9393140525367\n",
      "Average reward: 307.38485981519517\n",
      "Average reward: 306.85633143129337\n",
      "Average reward: 307.0633612228064\n",
      "Average reward: 276.57968000170365\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.7636053254381\n",
      "Average reward: 307.8620287011592\n",
      "Average reward: 283.06771152165066\n",
      "Average reward: 308.0599289752469\n",
      "Average reward: 308.2077844022501\n",
      "Average reward: 307.6574420420341\n",
      "Average reward: 307.2254472696212\n",
      "Average reward: 308.2208956037419\n",
      "Average reward: 308.3439964340716\n",
      "Average reward: 307.67631862298583\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.69615872979404\n",
      "Average reward: 308.09849131794743\n",
      "Average reward: 307.7444295786528\n",
      "Average reward: 307.930272952067\n",
      "Average reward: 255.09063923279575\n",
      "Average reward: 307.90023555976677\n",
      "Average reward: 208.21503377553245\n",
      "Average reward: 308.91902168841244\n",
      "Average reward: 307.8648544617145\n",
      "Average reward: 307.7310371220721\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.21278313602477\n",
      "Average reward: 308.3372875280901\n",
      "Average reward: 307.8076139591034\n",
      "Average reward: 307.9975037581951\n",
      "Average reward: 308.13085860098954\n",
      "Average reward: 307.3575080339813\n",
      "Average reward: 307.83414374070634\n",
      "Average reward: 308.00528705786485\n",
      "Average reward: 307.9659177366413\n",
      "Average reward: 275.8553755317413\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.4416309060348\n",
      "Average reward: 308.28313248691416\n",
      "Average reward: 307.62929068382624\n",
      "Average reward: 308.54326833238144\n",
      "Average reward: 308.3423756855921\n",
      "Average reward: 308.4965316845651\n",
      "Average reward: 307.4006584617671\n",
      "Average reward: 307.75451374409965\n",
      "Average reward: 308.4880565149416\n",
      "Average reward: 308.6160009682416\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.4216074074858\n",
      "Average reward: 308.83667535755916\n",
      "Average reward: 249.9408410107479\n",
      "Average reward: 308.7480114214435\n",
      "Average reward: 308.5855039073519\n",
      "Average reward: 308.2692618985298\n",
      "Average reward: 308.4678749884242\n",
      "Average reward: 308.8201717436608\n",
      "Average reward: 308.70973906162834\n",
      "Average reward: 309.0592959052686\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.5290517538738\n",
      "Average reward: 190.11925667586922\n",
      "Average reward: 308.89732158968695\n",
      "Average reward: 308.5758082853696\n",
      "Average reward: 262.1914259262866\n",
      "Average reward: 308.4274755037068\n",
      "Average reward: 273.5600984159049\n",
      "Average reward: 308.84426991730294\n",
      "Average reward: 308.7479722207228\n",
      "Average reward: 308.61118508412426\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 284.559570624771\n",
      "Average reward: 308.38746568908874\n",
      "Average reward: 244.59056007091718\n",
      "Average reward: 243.65899270202544\n",
      "Average reward: 307.70402277688476\n",
      "Average reward: 308.0567948200539\n",
      "Average reward: 256.6217726939658\n",
      "Average reward: 266.5259104222363\n",
      "Average reward: 242.78296868121296\n",
      "Average reward: 243.9481455168048\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.57216053000855\n",
      "Average reward: 307.78162453668153\n",
      "Average reward: 307.65578467012324\n",
      "Average reward: 307.70488853354146\n",
      "Average reward: 269.7457011102914\n",
      "Average reward: 308.352321066147\n",
      "Average reward: 307.7146923074396\n",
      "Average reward: 307.62173964725457\n",
      "Average reward: 307.41138410140985\n",
      "Average reward: 307.85903330116946\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.6413913439863\n",
      "Average reward: 308.51758892086883\n",
      "Average reward: 308.6294709363\n",
      "Average reward: 308.0872208241686\n",
      "Average reward: 308.1388772209915\n",
      "Average reward: 254.00050971826576\n",
      "Average reward: 308.25956252909265\n",
      "Average reward: 235.69000420321254\n",
      "Average reward: 250.74433337266495\n",
      "Average reward: 223.4642848775178\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.28753558410074\n",
      "Average reward: 308.2435979938604\n",
      "Average reward: 308.1823508336141\n",
      "Average reward: 308.18632164292325\n",
      "Average reward: 308.38381192137706\n",
      "Average reward: 203.6610549826602\n",
      "Average reward: 307.9599899861389\n",
      "Average reward: 261.5972948347953\n",
      "Average reward: 246.28196682398703\n",
      "Average reward: 308.27191294111617\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.41377573848064\n",
      "Average reward: 308.0791435104949\n",
      "Average reward: 308.6855318678805\n",
      "Average reward: 267.5300364441775\n",
      "Average reward: 308.34029007947385\n",
      "Average reward: 244.22028940026254\n",
      "Average reward: 252.9341799823192\n",
      "Average reward: 283.7325798947446\n",
      "Average reward: 307.75117774102625\n",
      "Average reward: 244.54496453508736\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.5524916484409\n",
      "Average reward: 307.3943572176389\n",
      "Average reward: 307.4416258962876\n",
      "Average reward: 307.6500791879574\n",
      "Average reward: 307.69716488674965\n",
      "Average reward: 307.66948934974266\n",
      "Average reward: 247.57283561301585\n",
      "Average reward: 276.11961791723536\n",
      "Average reward: 307.52196791939866\n",
      "Average reward: 307.46133968533167\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 307.57328454727224\n",
      "Average reward: 306.74398232901683\n",
      "Average reward: 267.4008873040208\n",
      "Average reward: 307.71577015504806\n",
      "Average reward: 307.3924590824862\n",
      "Average reward: 307.83866428278975\n",
      "Average reward: 307.8289067564206\n",
      "Average reward: 307.59473056978436\n",
      "Average reward: 307.887007728725\n",
      "Average reward: 308.11158716639613\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 270.50686032512266\n",
      "Average reward: 272.27213025323687\n",
      "Average reward: 308.43769579654617\n",
      "Average reward: 308.5130273841645\n",
      "Average reward: 308.61603473271146\n",
      "Average reward: 307.70579706832376\n",
      "Average reward: 282.3689528840901\n",
      "Average reward: 308.4297304901117\n",
      "Average reward: 308.4875530654307\n",
      "Average reward: 308.1852838568458\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.1427771083346\n",
      "Average reward: 269.1621393032467\n",
      "Average reward: 308.5313491956837\n",
      "Average reward: 308.96854935829924\n",
      "Average reward: 308.46875244744626\n",
      "Average reward: 308.24773593402443\n",
      "Average reward: 308.69408672357423\n",
      "Average reward: 308.76000936314466\n",
      "Average reward: 308.772326161769\n",
      "Average reward: 308.5127107136466\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.59773335442395\n",
      "Average reward: 308.58143115337515\n",
      "Average reward: 243.94325746360903\n",
      "Average reward: 309.0310080904013\n",
      "Average reward: 308.2782692807083\n",
      "Average reward: 308.8557962114238\n",
      "Average reward: 308.98755179808273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 308.4648104404857\n",
      "Average reward: 308.25701262738386\n",
      "Average reward: 308.6230843662523\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 308.8792710802081\n",
      "Average reward: 197.89162346548002\n",
      "Average reward: 309.01999029845894\n",
      "Average reward: 309.00704855000623\n",
      "Average reward: 309.257861925735\n",
      "Average reward: 265.3801567344783\n",
      "Average reward: 271.7842568940338\n",
      "Average reward: 309.2456337416773\n",
      "Average reward: 309.58298511900205\n",
      "Average reward: 308.87910195375605\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.2316721321375\n",
      "Average reward: 308.8396974199974\n",
      "Average reward: 308.58290968320506\n",
      "Average reward: 309.10525918813164\n",
      "Average reward: 308.62623258854416\n",
      "Average reward: 309.23850507812966\n",
      "Average reward: 265.55245880572767\n",
      "Average reward: 309.00773521623216\n",
      "Average reward: 278.54887312836644\n",
      "Average reward: 308.31589855964137\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.3245414418594\n",
      "Average reward: 308.9138046593354\n",
      "Average reward: 308.4579811840772\n",
      "Average reward: 308.8191949566233\n",
      "Average reward: 254.9036954261046\n",
      "Average reward: 308.84609867378526\n",
      "Average reward: 309.2865649240725\n",
      "Average reward: 308.96340654900325\n",
      "Average reward: 308.66929835670715\n",
      "Average reward: 251.91866387779072\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.1770110568551\n",
      "Average reward: 309.2580601263714\n",
      "Average reward: 309.45240464239987\n",
      "Average reward: 308.74287615426204\n",
      "Average reward: 308.8699791848369\n",
      "Average reward: 308.3279655432117\n",
      "Average reward: 309.4152824646574\n",
      "Average reward: 221.9069463314921\n",
      "Average reward: 191.6486318606717\n",
      "Average reward: 309.00535645480267\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.28785531706916\n",
      "Average reward: 309.73323902048327\n",
      "Average reward: 246.46085922053234\n",
      "Average reward: 309.4534212220173\n",
      "Average reward: 246.21065278336573\n",
      "Average reward: 308.7008324623079\n",
      "Average reward: 309.6788467511266\n",
      "Average reward: 279.0962097903716\n",
      "Average reward: 309.53175898494726\n",
      "Average reward: 309.29624349783353\n",
      "Saving model...\n",
      "Model saved\n",
      "Average reward: 309.072641883594\n",
      "Average reward: 309.8196817755264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:1:\n",
      "Process Process-1:2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 204, in make_worker\n",
      "    return GatheringWorker(i, env_producer, rollout_size, worker_queue, weights_queue)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/gather.py\", line 45, in __init__\n",
      "    self.get_experience()\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/gather.py\", line 77, in get_experience\n",
      "    action, a_prob, h_out, v_out = self.agent.get_sample(self.s0, self.cur_hidden_state)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/agent.py\", line 113, in get_sample\n",
      "    return self.policy.sample(state, hidden_state)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/policy.py\", line 277, in sample\n",
      "    self.state_inputs: np.array(state).reshape((1, -1))\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 204, in make_worker\n",
      "    return GatheringWorker(i, env_producer, rollout_size, worker_queue, weights_queue)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/gather.py\", line 45, in __init__\n",
      "    self.get_experience()\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/gather.py\", line 84, in get_experience\n",
      "    self.s0, r, self.terminal, _ = self.env.step(action)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\", line 15, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/imetomi/.local/lib/python3.6/site-packages/gym/envs/box2d/bipedal_walker.py\", line 394, in step\n",
      "    self.world.Step(1.0/FPS, 6*30, 2*30)\n",
      "KeyboardInterrupt\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/master.py\", line 198, in make_worker\n",
      "    return Worker(env_producer, i, q, w_in_queue)\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 44, in __init__\n",
      "    self.init_agent()\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 68, in init_agent\n",
      "    self.run()\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 83, in run\n",
      "    stats = self.compute_grads_and_stats()\n",
      "  File \"/home/imetomi/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/worker.py\", line 114, in compute_grads_and_stats\n",
      "    results.append(self.worker_queue.get())\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-346824fa3c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BipedalWalker-v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-5c7387a3fb78>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(env, gpu)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0menv_producer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvironmentProducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_producer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/master.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_producer)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/master.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Teaching-a-Robot-to-Walk-OpenAI-Gym/master.py\u001b[0m in \u001b[0;36mmerge_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_in_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start('BipedalWalker-v2', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
